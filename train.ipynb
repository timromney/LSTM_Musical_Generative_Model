{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the LSTM Model\n",
    "Running this notebook preprocesses the midi files and passes it to the neural network for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\timro\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import glob\n",
    "import pickle\n",
    "import numpy\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization as BatchNorm\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the values below in order to tweak the model's behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "memory_length = 16 # use 16, 32, 64, etc.\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function 'get_notes' retrieves every note and chord that occurs in all the midi files in the '/midi' directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes():\n",
    "    notes = []\n",
    "    for file in glob.glob(\"data/midi/*.mid\"):\n",
    "        midi = converter.parse(file)\n",
    "        print(\"Parsing %s\" % file)\n",
    "        notes_to_parse = None\n",
    "        \n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "            \n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "                \n",
    "    with open('data/notes', 'wb') as filepath:\n",
    "        pickle.dump(notes, filepath)\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function 'prepare_sequences' preprocesses the data input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, n_vocab, memory_len):\n",
    "    # get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    \n",
    "     # create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "    \n",
    "    network_input = []\n",
    "    network_output = []\n",
    "    \n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - memory_len, 1):\n",
    "        sequence_in = notes[i:i + memory_len]\n",
    "        sequence_out = notes[i + memory_len]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = numpy.reshape(network_input, (n_patterns, memory_len, 1))\n",
    "    \n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "\n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(network_input, n_vocab):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "                   recurrent_dropout=0.3, return_sequences=True))\n",
    "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, network_input, network_output, num_epochs):\n",
    "    \"\"\" train the neural network \"\"\"\n",
    "    filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0,\n",
    "                                 save_best_only=True, mode='min')\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    model.fit(network_input, network_output, epochs=num_epochs, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function trains the Neural Network to generate music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(memory_len, num_epochs):\n",
    "    notes = get_notes()\n",
    "    n_vocab = len(set(notes)) # get amount of pitch names\n",
    "    network_input, network_output = prepare_sequences(notes, n_vocab, memory_len)\n",
    "    model = create_network(network_input, n_vocab)\n",
    "    train(model, network_input, network_output, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run This to Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing data/midi\\0fithos.mid\n",
      "Parsing data/midi\\8.mid\n",
      "Parsing data/midi\\ahead_on_our_way_piano.mid\n",
      "Parsing data/midi\\AT.mid\n",
      "Parsing data/midi\\balamb.mid\n",
      "Parsing data/midi\\bcm.mid\n",
      "Parsing data/midi\\BlueStone_LastDungeon.mid\n",
      "Parsing data/midi\\braska.mid\n",
      "Parsing data/midi\\caitsith.mid\n",
      "Parsing data/midi\\Cids.mid\n",
      "Parsing data/midi\\cosmo.mid\n",
      "Parsing data/midi\\costadsol.mid\n",
      "Parsing data/midi\\dayafter.mid\n",
      "Parsing data/midi\\decisive.mid\n",
      "Parsing data/midi\\dontbeafraid.mid\n",
      "Parsing data/midi\\DOS.mid\n",
      "Parsing data/midi\\electric_de_chocobo.mid\n",
      "Parsing data/midi\\Eternal_Harvest.mid\n",
      "Parsing data/midi\\EyesOnMePiano.mid\n",
      "Parsing data/midi\\ff11_awakening_piano.mid\n",
      "Parsing data/midi\\ff1battp.mid\n",
      "Parsing data/midi\\FF3_Battle_(Piano).mid\n",
      "Parsing data/midi\\FF3_Third_Phase_Final_(Piano).mid\n",
      "Parsing data/midi\\ff4-airship.mid\n",
      "Parsing data/midi\\Ff4-BattleLust.mid\n",
      "Parsing data/midi\\ff4-fight1.mid\n",
      "Parsing data/midi\\ff4-town.mid\n",
      "Parsing data/midi\\FF4.mid\n",
      "Parsing data/midi\\ff4pclov.mid\n",
      "Parsing data/midi\\ff4_piano_collections-main_theme.mid\n",
      "Parsing data/midi\\FF6epitaph_piano.mid\n",
      "Parsing data/midi\\ff6shap.mid\n",
      "Parsing data/midi\\Ff7-Cinco.mid\n",
      "Parsing data/midi\\Ff7-Jenova_Absolute.mid\n",
      "Parsing data/midi\\ff7-mainmidi.mid\n",
      "Parsing data/midi\\Ff7-One_Winged.mid\n",
      "Parsing data/midi\\ff7themep.mid\n",
      "Parsing data/midi\\ff8-lfp.mid\n",
      "Parsing data/midi\\FF8_Shuffle_or_boogie_pc.mid\n",
      "Parsing data/midi\\FFIII_Edgar_And_Sabin_Piano.mid\n",
      "Parsing data/midi\\FFIXQuMarshP.mid\n",
      "Parsing data/midi\\FFIX_Piano.mid\n",
      "Parsing data/midi\\FFVII_BATTLE.mid\n",
      "Parsing data/midi\\FFX_-_Ending_Theme_(Piano_Version)_-_by_Angel_FF.mid\n",
      "Parsing data/midi\\Fiend_Battle_(Piano).mid\n",
      "Parsing data/midi\\Fierce_Battle_(Piano).mid\n",
      "Parsing data/midi\\figaro.mid\n",
      "Parsing data/midi\\Finalfantasy5gilgameshp.mid\n",
      "Parsing data/midi\\Finalfantasy6fanfarecomplete.mid\n",
      "Parsing data/midi\\Final_Fantasy_7_-_Judgement_Day_Piano.mid\n",
      "Parsing data/midi\\Final_Fantasy_Matouyas_Cave_Piano.mid\n",
      "Parsing data/midi\\fortresscondor.mid\n",
      "Parsing data/midi\\Fyw_piano.mid\n",
      "Parsing data/midi\\gerudo.mid\n",
      "Parsing data/midi\\goldsaucer.mid\n",
      "Parsing data/midi\\Gold_Silver_Rival_Battle.mid\n",
      "Parsing data/midi\\great_war.mid\n",
      "Parsing data/midi\\HighwindTakestotheSkies.mid\n",
      "Parsing data/midi\\In_Zanarkand.mid\n",
      "Parsing data/midi\\JENOVA.mid\n",
      "Parsing data/midi\\Kingdom_Hearts_Dearly_Beloved.mid\n",
      "Parsing data/midi\\Kingdom_Hearts_Traverse_Town.mid\n",
      "Parsing data/midi\\Life_Stream.mid\n",
      "Parsing data/midi\\lurk_in_dark.mid\n",
      "Parsing data/midi\\mining.mid\n",
      "Parsing data/midi\\Oppressed.mid\n",
      "Parsing data/midi\\OTD5YA.mid\n",
      "Parsing data/midi\\path_of_repentance.mid\n",
      "Parsing data/midi\\pkelite4.mid\n",
      "Parsing data/midi\\Rachel_Piano_tempofix.mid\n",
      "Parsing data/midi\\redwings.mid\n",
      "Parsing data/midi\\relmstheme-piano.mid\n",
      "Parsing data/midi\\roseofmay-piano.mid\n",
      "Parsing data/midi\\rufus.mid\n",
      "Parsing data/midi\\Rydia_pc.mid\n",
      "Parsing data/midi\\sandy.mid\n",
      "Parsing data/midi\\sera_.mid\n",
      "Parsing data/midi\\sobf.mid\n",
      "Parsing data/midi\\Still_Alive-1.mid\n",
      "Parsing data/midi\\Suteki_Da_Ne_(Piano_Version).mid\n",
      "Parsing data/midi\\thenightmarebegins.mid\n",
      "Parsing data/midi\\thoughts.mid\n",
      "Parsing data/midi\\tifap.mid\n",
      "Parsing data/midi\\tpirtsd-piano.mid\n",
      "Parsing data/midi\\traitor.mid\n",
      "Parsing data/midi\\ultimafro.mid\n",
      "Parsing data/midi\\ultros.mid\n",
      "Parsing data/midi\\VincentPiano.mid\n",
      "Parsing data/midi\\ViviinAlexandria.mid\n",
      "Parsing data/midi\\waltz_de_choco.mid\n",
      "Parsing data/midi\\Zelda_Overworld.mid\n",
      "Parsing data/midi\\z_aeristhemepiano.mid\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Train on 57161 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-fbdd4e861e91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmemory_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-70820024d865>\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(memory_len, num_epochs)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mnetwork_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_vocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_vocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-0b865df75daa>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, network_input, network_output, num_epochs)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mcallbacks_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    807\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 809\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    664\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 666\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    667\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3788\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3790\u001b[1;33m     \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3791\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m(op_input_list)\u001b[0m\n\u001b[0;32m    628\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 630\u001b[1;33m       \u001b[0m_initialize_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[1;34m(session)\u001b[0m\n\u001b[0;32m   1063\u001b[0m       \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1064\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1065\u001b[1;33m       \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariables_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    956\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 958\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    959\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1181\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1182\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_network(memory_length, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing data/midi\\0fithos.mid\n",
      "Parsing data/midi\\8.mid\n",
      "Parsing data/midi\\ahead_on_our_way_piano.mid\n",
      "Parsing data/midi\\AT.mid\n",
      "Parsing data/midi\\balamb.mid\n",
      "Parsing data/midi\\bcm.mid\n",
      "Parsing data/midi\\BlueStone_LastDungeon.mid\n",
      "Parsing data/midi\\braska.mid\n",
      "Parsing data/midi\\caitsith.mid\n",
      "Parsing data/midi\\Cids.mid\n",
      "Parsing data/midi\\cosmo.mid\n",
      "Parsing data/midi\\costadsol.mid\n",
      "Parsing data/midi\\dayafter.mid\n",
      "Parsing data/midi\\decisive.mid\n",
      "Parsing data/midi\\dontbeafraid.mid\n",
      "Parsing data/midi\\DOS.mid\n",
      "Parsing data/midi\\electric_de_chocobo.mid\n",
      "Parsing data/midi\\Eternal_Harvest.mid\n",
      "Parsing data/midi\\EyesOnMePiano.mid\n",
      "Parsing data/midi\\ff11_awakening_piano.mid\n",
      "Parsing data/midi\\ff1battp.mid\n",
      "Parsing data/midi\\FF3_Battle_(Piano).mid\n",
      "Parsing data/midi\\FF3_Third_Phase_Final_(Piano).mid\n",
      "Parsing data/midi\\ff4-airship.mid\n",
      "Parsing data/midi\\Ff4-BattleLust.mid\n",
      "Parsing data/midi\\ff4-fight1.mid\n",
      "Parsing data/midi\\ff4-town.mid\n",
      "Parsing data/midi\\FF4.mid\n",
      "Parsing data/midi\\ff4pclov.mid\n",
      "Parsing data/midi\\ff4_piano_collections-main_theme.mid\n",
      "Parsing data/midi\\FF6epitaph_piano.mid\n",
      "Parsing data/midi\\ff6shap.mid\n",
      "Parsing data/midi\\Ff7-Cinco.mid\n",
      "Parsing data/midi\\Ff7-Jenova_Absolute.mid\n",
      "Parsing data/midi\\ff7-mainmidi.mid\n",
      "Parsing data/midi\\Ff7-One_Winged.mid\n",
      "Parsing data/midi\\ff7themep.mid\n",
      "Parsing data/midi\\ff8-lfp.mid\n",
      "Parsing data/midi\\FF8_Shuffle_or_boogie_pc.mid\n",
      "Parsing data/midi\\FFIII_Edgar_And_Sabin_Piano.mid\n",
      "Parsing data/midi\\FFIXQuMarshP.mid\n",
      "Parsing data/midi\\FFIX_Piano.mid\n",
      "Parsing data/midi\\FFVII_BATTLE.mid\n",
      "Parsing data/midi\\FFX_-_Ending_Theme_(Piano_Version)_-_by_Angel_FF.mid\n",
      "Parsing data/midi\\Fiend_Battle_(Piano).mid\n",
      "Parsing data/midi\\Fierce_Battle_(Piano).mid\n",
      "Parsing data/midi\\figaro.mid\n",
      "Parsing data/midi\\Finalfantasy5gilgameshp.mid\n",
      "Parsing data/midi\\Finalfantasy6fanfarecomplete.mid\n",
      "Parsing data/midi\\Final_Fantasy_7_-_Judgement_Day_Piano.mid\n",
      "Parsing data/midi\\Final_Fantasy_Matouyas_Cave_Piano.mid\n",
      "Parsing data/midi\\fortresscondor.mid\n",
      "Parsing data/midi\\Fyw_piano.mid\n",
      "Parsing data/midi\\gerudo.mid\n",
      "Parsing data/midi\\goldsaucer.mid\n",
      "Parsing data/midi\\Gold_Silver_Rival_Battle.mid\n",
      "Parsing data/midi\\great_war.mid\n",
      "Parsing data/midi\\HighwindTakestotheSkies.mid\n",
      "Parsing data/midi\\In_Zanarkand.mid\n",
      "Parsing data/midi\\JENOVA.mid\n",
      "Parsing data/midi\\Kingdom_Hearts_Dearly_Beloved.mid\n",
      "Parsing data/midi\\Kingdom_Hearts_Traverse_Town.mid\n",
      "Parsing data/midi\\Life_Stream.mid\n",
      "Parsing data/midi\\lurk_in_dark.mid\n",
      "Parsing data/midi\\mining.mid\n",
      "Parsing data/midi\\Oppressed.mid\n",
      "Parsing data/midi\\OTD5YA.mid\n",
      "Parsing data/midi\\path_of_repentance.mid\n",
      "Parsing data/midi\\pkelite4.mid\n",
      "Parsing data/midi\\Rachel_Piano_tempofix.mid\n",
      "Parsing data/midi\\redwings.mid\n",
      "Parsing data/midi\\relmstheme-piano.mid\n",
      "Parsing data/midi\\roseofmay-piano.mid\n",
      "Parsing data/midi\\rufus.mid\n",
      "Parsing data/midi\\Rydia_pc.mid\n",
      "Parsing data/midi\\sandy.mid\n",
      "Parsing data/midi\\sera_.mid\n",
      "Parsing data/midi\\sobf.mid\n",
      "Parsing data/midi\\Still_Alive-1.mid\n",
      "Parsing data/midi\\Suteki_Da_Ne_(Piano_Version).mid\n",
      "Parsing data/midi\\thenightmarebegins.mid\n",
      "Parsing data/midi\\thoughts.mid\n",
      "Parsing data/midi\\tifap.mid\n",
      "Parsing data/midi\\tpirtsd-piano.mid\n",
      "Parsing data/midi\\traitor.mid\n",
      "Parsing data/midi\\ultimafro.mid\n",
      "Parsing data/midi\\ultros.mid\n",
      "Parsing data/midi\\VincentPiano.mid\n",
      "Parsing data/midi\\ViviinAlexandria.mid\n",
      "Parsing data/midi\\waltz_de_choco.mid\n",
      "Parsing data/midi\\Zelda_Overworld.mid\n",
      "Parsing data/midi\\z_aeristhemepiano.mid\n",
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "           OPERATION           DATA DIMENSIONS   WEIGHTS(N)   WEIGHTS(%)\n",
      "\n",
      "               Input   #####     16    1\n",
      "                LSTM   LLLLL -------------------   1052672    19.2%\n",
      "                tanh   #####     16  512\n",
      "                LSTM   LLLLL -------------------   2099200    38.3%\n",
      "                tanh   #####     16  512\n",
      "                LSTM   LLLLL -------------------   2099200    38.3%\n",
      "                tanh   #####         512\n",
      "  BatchNormalization    μ|σ  -------------------      2048     0.0%\n",
      "                       #####         512\n",
      "             Dropout    | || -------------------         0     0.0%\n",
      "                       #####         512\n",
      "               Dense   XXXXX -------------------    131328     2.4%\n",
      "                relu   #####         256\n",
      "  BatchNormalization    μ|σ  -------------------      1024     0.0%\n",
      "                       #####         256\n",
      "             Dropout    | || -------------------         0     0.0%\n",
      "                       #####         256\n",
      "               Dense   XXXXX -------------------     92006     1.7%\n",
      "             softmax   #####         358\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "from keras_sequential_ascii import keras2ascii\n",
    "\n",
    "notes = get_notes()\n",
    "n_vocab = len(set(notes)) # get amount of pitch names\n",
    "network_input, network_output = prepare_sequences(notes, n_vocab, memory_length)\n",
    "model = create_network(network_input, n_vocab)\n",
    "\n",
    "keras2ascii(model)\n",
    "    \n",
    "tf.keras.utils.plot_model(model,to_file=\"model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
